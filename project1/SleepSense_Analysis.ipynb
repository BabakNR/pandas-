{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c33a112-9343-4cec-8028-935fcf18382b",
   "metadata": {},
   "source": [
    "# SleepSense: Sleep Quality Analysis and Prediction\n",
    "\n",
    "This Jupyter notebook analyzes wearable sensor data to predict sleep quality using **Pandas** and **NumPy**. It includes:\n",
    "- Generating a sample dataset with 1000 rows.\n",
    "- Preprocessing data (cleaning and feature engineering).\n",
    "- Statistical analysis (correlations and summaries).\n",
    "- Predicting sleep quality using a simple threshold-based model.\n",
    "\n",
    "## Dataset\n",
    "The generated dataset (`data/sleep_data.csv`) contains:\n",
    "- `timestamp`: Date and time of record (datetime).\n",
    "- `heart_rate`: Heart rate in beats per minute (float, 50-100).\n",
    "- `sleep_duration`: Sleep duration in hours (float, 4-9).\n",
    "- `body_movement`: Body movement intensity (float, 0-30).\n",
    "- `sleep_quality`: Sleep quality label (string: good, average, poor).\n",
    "\n",
    "## Outputs\n",
    "- Dataset previews (raw and cleaned).\n",
    "- Correlation matrix of numeric features.\n",
    "- Statistical summary by sleep quality.\n",
    "- Predicted sleep quality with accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb07ed4a-3e65-4a6e-ba24-9b3954156162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 1: Generate sample dataset with realistic patterns\n",
    "def generate_data():\n",
    "    \"\"\"Generate a sample dataset with 1000 rows of wearable sensor data and save to CSV.\"\"\"\n",
    "    os.makedirs('data', exist_ok=True)  # Create data directory if it doesn't exist\n",
    "    n = 1000\n",
    "    data = {\n",
    "        'timestamp': pd.date_range(start='2023-01-01', periods=n, freq='H'),  # Hourly timestamps\n",
    "        'sleep_duration': np.random.uniform(4, 9, n),  # Sleep duration: 4-9 hours\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Generate heart_rate and body_movement with patterns based on sleep quality\n",
    "    df['sleep_quality'] = np.random.choice(['good', 'average', 'poor'], n, p=[0.4, 0.4, 0.2])\n",
    "    df['heart_rate'] = np.where(\n",
    "        df['sleep_quality'] == 'good', np.random.normal(55, 5, n).clip(50, 70),\n",
    "        np.where(df['sleep_quality'] == 'average', np.random.normal(65, 7, n).clip(50, 80),\n",
    "                 np.random.normal(75, 8, n).clip(60, 100))\n",
    "    )\n",
    "    df['body_movement'] = np.where(\n",
    "        df['sleep_quality'] == 'good', np.random.uniform(0, 10, n),\n",
    "        np.where(df['sleep_quality'] == 'average', np.random.uniform(5, 20, n),\n",
    "                 np.random.uniform(15, 30, n))\n",
    "    )\n",
    "    \n",
    "    df.to_csv('data/sleep_data.csv', index=False)  # Save dataset to CSV\n",
    "    print(\"Dataset saved to 'data/sleep_data.csv'.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53785a7-506d-43c6-91f5-7c9e57ef8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and preprocess data\n",
    "def load_data(file_path='data/sleep_data.csv'):\n",
    "    \"\"\"Load CSV file and convert timestamp column to datetime format.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Clean data by filling missing values and removing outliers.\"\"\"\n",
    "    numeric_cols = ['heart_rate', 'sleep_duration', 'body_movement']\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())  # Fill missing values with mean\n",
    "    df = df[(df['heart_rate'] >= 40) & (df['heart_rate'] <= 120)]  # Filter heart rate: 40-120\n",
    "    df = df[(df['sleep_duration'] >= 0) & (df['sleep_duration'] <= 12)]  # Filter sleep duration: 0-12 hours\n",
    "    df = df[df['body_movement'] >= 0]  # Filter body movement: non-negative\n",
    "    return df\n",
    "\n",
    "def add_features(df):\n",
    "    \"\"\"Add new features like daily average heart rate and normalized sleep duration.\"\"\"\n",
    "    df['date'] = df['timestamp'].dt.date  # Extract date for grouping\n",
    "    daily_avg_hr = df.groupby('date')['heart_rate'].mean().reset_index()\n",
    "    daily_avg_hr.columns = ['date', 'daily_avg_heart_rate']\n",
    "    df = df.merge(daily_avg_hr, on='date', how='left')  # Merge daily avg heart rate\n",
    "    df['norm_sleep_duration'] = (df['sleep_duration'] - df['sleep_duration'].mean()) / df['sleep_duration'].std()  # Normalize sleep duration\n",
    "    df = df.drop(columns=['date'])  # Remove temporary date column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be1fb0d9-7311-4fa0-9365-e7eed4a7ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Analyze data\n",
    "def calculate_correlations(df):\n",
    "    \"\"\"Calculate correlation matrix for numeric columns.\"\"\"\n",
    "    numeric_cols = ['heart_rate', 'sleep_duration', 'body_movement', 'daily_avg_heart_rate', 'norm_sleep_duration']\n",
    "    correlations = df[numeric_cols].corr()  # Compute Pearson correlation\n",
    "    return correlations\n",
    "\n",
    "def summarize_by_quality(df):\n",
    "    \"\"\"Summarize numeric columns grouped by sleep quality.\"\"\"\n",
    "    summary = df.groupby('sleep_quality').agg({\n",
    "        'heart_rate': ['mean', 'std'],\n",
    "        'sleep_duration': ['mean', 'std'],\n",
    "        'body_movement': ['mean', 'std']\n",
    "    }).round(2)  # Round to 2 decimal places\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57bf0a60-b8a6-454d-857a-7daf2837a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare data for modeling\n",
    "def prepare_data_for_model(df):\n",
    "    \"\"\"Prepare features and labels for machine learning model.\"\"\"\n",
    "    features = ['heart_rate', 'sleep_duration', 'body_movement', 'daily_avg_heart_rate', 'norm_sleep_duration']\n",
    "    X = df[features]\n",
    "    y = df['sleep_quality']\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8819295-6eee-48bb-bdd2-7f37fe9b36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train and predict with Logistic Regression\n",
    "def train_predict_model(X, y):\n",
    "    \"\"\"Train a Logistic Regression model and predict sleep quality.\"\"\"\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train Logistic Regression model\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return model, accuracy, y_pred, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fd816d5-f022-4315-9fb5-ba71d8ad2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Apply predictions to entire dataset\n",
    "def apply_predictions(df, model, scaler):\n",
    "    \"\"\"Apply trained model to entire dataset for predictions.\"\"\"\n",
    "    features = ['heart_rate', 'sleep_duration', 'body_movement', 'daily_avg_heart_rate', 'norm_sleep_duration']\n",
    "    X = df[features]\n",
    "    X_scaled = scaler.transform(X)\n",
    "    df['predicted_quality'] = model.predict(X_scaled)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169ae5e8-206e-4f0a-b4b9-2ffbcb5927b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to 'data/sleep_data.csv'.\n",
      "Raw Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_28044\\2884110760.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  'timestamp': pd.date_range(start='2023-01-01', periods=n, freq='H'),  # Hourly timestamps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>body_movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>5.872701</td>\n",
       "      <td>good</td>\n",
       "      <td>50.610087</td>\n",
       "      <td>2.571524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>8.753572</td>\n",
       "      <td>average</td>\n",
       "      <td>67.727299</td>\n",
       "      <td>7.470963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>7.659970</td>\n",
       "      <td>poor</td>\n",
       "      <td>60.279378</td>\n",
       "      <td>20.013230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>6.993292</td>\n",
       "      <td>average</td>\n",
       "      <td>68.742404</td>\n",
       "      <td>9.308865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>4.780093</td>\n",
       "      <td>poor</td>\n",
       "      <td>80.124343</td>\n",
       "      <td>20.115718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  sleep_duration sleep_quality  heart_rate  body_movement\n",
       "0 2023-01-01 00:00:00        5.872701          good   50.610087       2.571524\n",
       "1 2023-01-01 01:00:00        8.753572       average   67.727299       7.470963\n",
       "2 2023-01-01 02:00:00        7.659970          poor   60.279378      20.013230\n",
       "3 2023-01-01 03:00:00        6.993292       average   68.742404       9.308865\n",
       "4 2023-01-01 04:00:00        4.780093          poor   80.124343      20.115718"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the pipeline\n",
    "# Generate and load data\n",
    "df = generate_data()\n",
    "df = load_data()  # Reload to ensure consistency\n",
    "print('Raw Data:')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c0b44d-7bf4-44f2-a213-01e679964779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Matrix:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['daily_avg_heart_rate', 'norm_sleep_duration'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Analyze data\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCorrelation Matrix:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(calculate_correlations(df))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcalculate_correlations\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calculate correlation matrix for numeric columns.\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m numeric_cols = [\u001b[33m'\u001b[39m\u001b[33mheart_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msleep_duration\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbody_movement\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdaily_avg_heart_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnorm_sleep_duration\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m correlations = df[numeric_cols].corr()  \u001b[38;5;66;03m# Compute Pearson correlation\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m correlations\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns._get_indexer_strict(key, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28mself\u001b[39m._raise_if_missing(keyarr, indexer, axis_name)\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['daily_avg_heart_rate', 'norm_sleep_duration'] not in index\""
     ]
    }
   ],
   "source": [
    "# Analyze data\n",
    "print('\\nCorrelation Matrix:')\n",
    "print(calculate_correlations(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "965de5e8-fcc8-4981-b9f3-2163070a5bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary by Sleep Quality:\n",
      "              heart_rate       sleep_duration       body_movement      \n",
      "                    mean   std           mean   std          mean   std\n",
      "sleep_quality                                                          \n",
      "average            65.50  7.12           6.53  1.47         12.48  4.32\n",
      "good               55.33  4.36           6.42  1.46          5.05  2.83\n",
      "poor               74.76  7.79           6.37  1.44         22.50  4.17\n"
     ]
    }
   ],
   "source": [
    "print('\\nSummary by Sleep Quality:')\n",
    "print(summarize_by_quality(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5803657f-0f2c-4953-bdb6-e0d365da8947",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['daily_avg_heart_rate', 'norm_sleep_duration'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Prepare data and train model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X, y, scaler = prepare_data_for_model(df)\n\u001b[32m      3\u001b[39m model, accuracy, y_pred, y_test = train_predict_model(X, y)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mModel Accuracy on Test Set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mprepare_data_for_model\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Prepare features and labels for machine learning model.\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m features = [\u001b[33m'\u001b[39m\u001b[33mheart_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msleep_duration\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbody_movement\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdaily_avg_heart_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnorm_sleep_duration\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m X = df[features]\n\u001b[32m      6\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33msleep_quality\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Normalize features\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns._get_indexer_strict(key, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28mself\u001b[39m._raise_if_missing(keyarr, indexer, axis_name)\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['daily_avg_heart_rate', 'norm_sleep_duration'] not in index\""
     ]
    }
   ],
   "source": [
    "# Prepare data and train model\n",
    "X, y, scaler = prepare_data_for_model(df)\n",
    "model, accuracy, y_pred, y_test = train_predict_model(X, y)\n",
    "print(f'\\nModel Accuracy on Test Set: {accuracy:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c952882-053a-4ad1-ab8d-529e540c3003",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Apply predictions to entire dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = apply_predictions(df, model, scaler)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mData with Predicted Sleep Quality:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msleep_quality\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpredicted_quality\u001b[39m\u001b[33m'\u001b[39m]].head())\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply predictions to entire dataset\n",
    "df = apply_predictions(df, model, scaler)\n",
    "print('\\nData with Predicted Sleep Quality:')\n",
    "print(df[['timestamp', 'sleep_quality', 'predicted_quality']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a48bd9d-1fb6-44ce-bc74-bfb08d463031",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predicted_quality'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._engine.get_loc(casted_key)\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'predicted_quality'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Calculate overall prediction accuracy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m overall_accuracy = (df[\u001b[33m'\u001b[39m\u001b[33msleep_quality\u001b[39m\u001b[33m'\u001b[39m] == df[\u001b[33m'\u001b[39m\u001b[33mpredicted_quality\u001b[39m\u001b[33m'\u001b[39m]).mean()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOverall Prediction Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Users\\Ali\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'predicted_quality'"
     ]
    }
   ],
   "source": [
    "# Calculate overall prediction accuracy\n",
    "overall_accuracy = (df['sleep_quality'] == df['predicted_quality']).mean()\n",
    "print(f'\\nOverall Prediction Accuracy: {overall_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bf87f-4eb8-467e-92ec-be3c80af4531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea46d2-a7f1-42be-a5c2-8d78a3512bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedfa697-79a0-4a18-a504-b4d7dedaa6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a83e81-9b18-41ee-b5d7-5c90c6e6c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 1: Generate sample dataset with realistic patterns\n",
    "def generate_data():\n",
    "    \"\"\"Generate a sample dataset with 1000 rows of wearable sensor data and save to CSV.\"\"\"\n",
    "    os.makedirs('data', exist_ok=True)  # Create data directory if it doesn't exist\n",
    "    n = 1000\n",
    "    data = {\n",
    "        'timestamp': pd.date_range(start='2023-01-01', periods=n, freq='H'),  # Hourly timestamps\n",
    "        'sleep_duration': np.random.uniform(4, 9, n),  # Sleep duration: 4-9 hours\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Generate heart_rate and body_movement with patterns based on sleep quality\n",
    "    df['sleep_quality'] = np.random.choice(['good', 'average', 'poor'], n, p=[0.4, 0.4, 0.2])\n",
    "    df['heart_rate'] = np.where(\n",
    "        df['sleep_quality'] == 'good', np.random.normal(55, 5, n).clip(50, 70),\n",
    "        np.where(df['sleep_quality'] == 'average', np.random.normal(65, 7, n).clip(50, 80),\n",
    "                 np.random.normal(75, 8, n).clip(60, 100))\n",
    "    )\n",
    "    df['body_movement'] = np.where(\n",
    "        df['sleep_quality'] == 'good', np.random.uniform(0, 10, n),\n",
    "        np.where(df['sleep_quality'] == 'average', np.random.uniform(5, 20, n),\n",
    "                 np.random.uniform(15, 30, n))\n",
    "    )\n",
    "    \n",
    "    df.to_csv('data/sleep_data.csv', index=False)  # Save dataset to CSV\n",
    "    print(\"Dataset saved to 'data/sleep_data.csv'.\")\n",
    "    return df\n",
    "\n",
    "# Step 2: Load and preprocess data\n",
    "def load_data(file_path='data/sleep_data.csv'):\n",
    "    \"\"\"Load CSV file and convert timestamp column to datetime format.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Clean data by filling missing values and removing outliers.\"\"\"\n",
    "    numeric_cols = ['heart_rate', 'sleep_duration', 'body_movement']\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())  # Fill missing values with mean\n",
    "    df = df[(df['heart_rate'] >= 40) & (df['heart_rate'] <= 120)]  # Filter heart rate: 40-120\n",
    "    df = df[(df['sleep_duration'] >= 0) & (df['sleep_duration'] <= 12)]  # Filter sleep duration: 0-12 hours\n",
    "    df = df[df['body_movement'] >= 0]  # Filter body movement: non-negative\n",
    "    return df\n",
    "\n",
    "def add_features(df):\n",
    "    \"\"\"Add new features like daily average heart rate and normalized sleep duration.\"\"\"\n",
    "    df['date'] = df['timestamp'].dt.date  # Extract date for grouping\n",
    "    daily_avg_hr = df.groupby('date')['heart_rate'].mean().reset_index()\n",
    "    daily_avg_hr.columns = ['date', 'daily_avg_heart_rate']\n",
    "    df = df.merge(daily_avg_hr, on='date', how='left')  # Merge daily avg heart rate\n",
    "    df['norm_sleep_duration'] = (df['sleep_duration'] - df['sleep_duration'].mean()) / df['sleep_duration'].std()  # Normalize sleep duration\n",
    "    df = df.drop(columns=['date'])  # Remove temporary date column\n",
    "    return df\n",
    "\n",
    "# Step 3: Analyze data\n",
    "def calculate_correlations(df):\n",
    "    \"\"\"Calculate correlation matrix for numeric columns.\"\"\"\n",
    "    numeric_cols = ['heart_rate', 'sleep_duration', 'body_movement', 'daily_avg_heart_rate', 'norm_sleep_duration']\n",
    "    correlations = df[numeric_cols].corr()  # Compute Pearson correlation\n",
    "    return correlations\n",
    "\n",
    "def summarize_by_quality(df):\n",
    "    \"\"\"Summarize numeric columns grouped by sleep quality.\"\"\"\n",
    "    summary = df.groupby('sleep_quality').agg({\n",
    "        'heart_rate': ['mean', 'std'],\n",
    "        'sleep_duration': ['mean', 'std'],\n",
    "        'body_movement': ['mean', 'std']\n",
    "    }).round(2)  # Round to 2 decimal places\n",
    "    return summary\n",
    "\n",
    "# Step 4: Prepare data for modeling\n",
    "def prepare_data_for_model(df):\n",
    "    \"\"\"Prepare features and labels for machine learning model.\"\"\"\n",
    "    features = ['heart_rate', 'sleep_duration', 'body_movement', 'daily_avg_heart_rate', 'norm_sleep_duration']\n",
    "    X = df[features]\n",
    "    y = df['sleep_quality']\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y, scaler\n",
    "\n",
    "# Step 5: Train and predict with Logistic Regression\n",
    "def train_predict_model(X, y):\n",
    "    \"\"\"Train a Logistic Regression model and predict sleep quality.\"\"\"\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train Logistic Regression model\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return model, accuracy, y_pred, y_test\n",
    "\n",
    "# Step 6: Apply predictions to entire dataset\n",
    "def apply_predictions(df, model, scaler):\n",
    "    \"\"\"Apply trained model to entire dataset for predictions.\"\"\"\n",
    "    features = ['heart_rate', 'sleep_duration', 'body_movement', 'daily_avg_heart_rate', 'norm_sleep_duration']\n",
    "    X = df[features]\n",
    "    X_scaled = scaler.transform(X)\n",
    "    df['predicted_quality'] = model.predict(X_scaled)\n",
    "    return df\n",
    "\n",
    "# Execute the pipeline\n",
    "# Generate and load data\n",
    "df = generate_data()\n",
    "df = load_data()  # Reload to ensure consistency\n",
    "print('Raw Data:')\n",
    "print(df.head())\n",
    "\n",
    "# Preprocess data\n",
    "df = clean_data(df)\n",
    "df = add_features(df)\n",
    "print('\\nCleaned Data with New Features:')\n",
    "print(df.head())\n",
    "\n",
    "# Analyze data\n",
    "print('\\nCorrelation Matrix:')\n",
    "print(calculate_correlations(df))\n",
    "\n",
    "print('\\nSummary by Sleep Quality:')\n",
    "print(summarize_by_quality(df))\n",
    "\n",
    "# Prepare data and train model\n",
    "X, y, scaler = prepare_data_for_model(df)\n",
    "model, accuracy, y_pred, y_test = train_predict_model(X, y)\n",
    "print(f'\\nModel Accuracy on Test Set: {accuracy:.2%}')\n",
    "\n",
    "# Apply predictions to entire dataset\n",
    "df = apply_predictions(df, model, scaler)\n",
    "print('\\nData with Predicted Sleep Quality:')\n",
    "print(df[['timestamp', 'sleep_quality', 'predicted_quality']].head())\n",
    "\n",
    "# Calculate overall prediction accuracy\n",
    "overall_accuracy = (df['sleep_quality'] == df['predicted_quality']).mean()\n",
    "print(f'\\nOverall Prediction Accuracy: {overall_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c620f-86cd-44fc-956e-8703b2c3c89f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
